{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Enhancing accuracy in LLM multi-modal vision use cases on Amazon Bedrock\n",
    "\n",
    "As Large Language Models (LLMs) evolve to process multiple modalities, we face challenges reminiscent of early text-based LLMs: basic inconsistency, inaccuracy, and hallucinations. \n",
    "This notebook focus on techniques to increase the accuracy of vision use cases using various techniques. Inlucded is a quick introduction to AWS Gen AI services landscape and how to get started with using Anthropic Claude and other LLMs on Amazon Bedrock."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's deep dive into a specific vision task of Structured OCR\n",
    "\n",
    "The goal is to A. idetify and read the (Hebrew) text on the page. B. Figure out the structure of the page. C. populate the structure with the text and output it (as Json).\n",
    "Note that this example includes Hebrew text, some block lettes, some handwritten.\n",
    "\n",
    "<img title=\"Sturctured OCR Task\" src=\"./images/structured ocr.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How can we accomplish this on AWS?\n",
    "<img title=\"aws stack.png\" src=\"./images/aws stack.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use a multi-modal LLM for this task\n",
    "Let's proceed with using Anthropic Claude Sonnet 3.5 multi modal on Amazon Bedrock. We get a lot of abilities out of the box and we get started in minutes.\n",
    "\n",
    "#### What vision use cases can it do?\n",
    "- Classification (+ few shots)\n",
    "- Object Detection\n",
    "- Scene insights extraction (emotions)\n",
    "- (Structured) OCR\n",
    "- Content moderation\n",
    "- Custome tasks - you name it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we call A bedrock model with an image?\n",
    "\n",
    "```python \n",
    "    # 1) Read the image bytes\n",
    "    with open(input_image, \"rb\") as f:\n",
    "        image_bytes = f.read()\n",
    "\n",
    "    # 2) Create a message(s) with text or image\n",
    "    message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"image\": {\n",
    "                    \"format\": \"jpeg\",\n",
    "                    \"source\": {\n",
    "                        \"bytes\": image_bytes\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # 3) Invoke Converse API (same exact API for different model vendors + native tools support). Supported by LangChain.\n",
    "    response = bedrock_client.converse(\n",
    "        modelId = model_id,\n",
    "        messages = [messages,],\n",
    "        system = system_prompts,\n",
    "        inferenceConfig = inference_config,\n",
    "        #additionalModelRequestFields = additional_model_fields\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./.venv/lib/python3.10/site-packages (24.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement json (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for json\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pip install --upgrade pip\n",
    "%pip install boto3 --quiet\n",
    "%pip install botocore --quiet\n",
    "%pip install json --quiet\n",
    "import base64\n",
    "import boto3\n",
    "import json\n",
    "from IPython.display import Image\n",
    "from json_eval import compare_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating message with model us.anthropic.claude-3-5-sonnet-20240620-v1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role: assistant\n",
      "Text: I'll extract the menu information from the image and structure it according to the provided JSON schema. I'll go through the menu from right to left and top to bottom, as it's written in Hebrew.\n",
      "\n",
      "{\n",
      "  \"categories\": [\n",
      "    {\n",
      "      \"name\": \"×ª×¤×¨×™×˜\",\n",
      "      \"dishes\": [\n",
      "        {\n",
      "          \"name\": \"×¤×™×¦×” ××™×©×™×ª (S)\",\n",
      "          \"price\": 20\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×¤×™×¦×” ××©×¤×—×ª×™×ª (L)\",\n",
      "          \"price\": 29\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×¤×™×¦×” ×¢× ×§×™×ª (XL)\",\n",
      "          \"price\": 49\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"××©×¤×—×ª×™×ª ×˜×‘×¢×•× ×™×ª\",\n",
      "          \"price\": 40\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"××©×¤×—×ª×™×ª ×œ×œ× ×’×œ×•×˜×Ÿ\",\n",
      "          \"price\": 45\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×”××œ×¦×ª ×”×©×£ ×¤×™×¦×” ×™×•×•× ×™×ª\",\n",
      "          \"price\": 49,\n",
      "          \"description\": \"×¢×’×‘× ×™×”,×‘×¦×œ,×–×™×ª×™× ×©×—×•×¨×™×,×‘×•×œ×’×¨×™×ª\"\n",
      "        }\n",
      "      ],\n",
      "      \"extraInfo\": [\n",
      "        \"×ª×•×¡×¤×ª ×©×•××©×•× ×‘×§×¦×•×•×ª ×”×¤×™×¦×” 2 â‚ª\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"×œ×—× ×©×•×\",\n",
      "      \"dishes\": [\n",
      "        {\n",
      "          \"name\": \"×œ×—× ×©×•× ××™×©×™\",\n",
      "          \"price\": 15\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×œ×—× ×©×•× ××™×©×™ ××•×§×¨×\",\n",
      "          \"price\": 18\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×œ×—× ×©×•× ××©×¤×—×ª×™\",\n",
      "          \"price\": 26\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×œ×—× ×©×•× ××©×¤×—×ª×™ ××•×§×¨×\",\n",
      "          \"price\": 33\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×œ×—× ×©×•× ×”×‘×™×ª (L)\",\n",
      "          \"price\": 45,\n",
      "          \"description\": \"(×‘×ª×•×¡×¤×ª ×¢×’×‘× ×™×”, ××•×¦×¨×œ×” ×•×‘×•×œ×’×¨×™×ª)\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"×¡×œ×˜×™×\",\n",
      "      \"dishes\": [\n",
      "        {\n",
      "          \"name\": \"×¡×œ×˜ ×‘×•×œ×’×¨×™×ª\",\n",
      "          \"price\": 34,\n",
      "          \"description\": \"×—×¡×”, ××œ×¤×¤×•×Ÿ, ×¢×’×‘× ×™×•×ª ×©×¨×™, ×ª×™×¨×¡, ×–×™×ª×™× ×©×—×•×¨×™× ×•×‘×•×œ×’×¨×™×ª\"\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×¡×œ×˜ ×˜×•× ×”\",\n",
      "          \"price\": 34,\n",
      "          \"description\": \"×—×¡×”, ××œ×¤×¤×•×Ÿ, ×¢×’×‘× ×™×•×ª ×©×¨×™, ×ª×™×¨×¡, ×–×™×ª×™× ×©×—×•×¨×™× ×•×˜×•× ×”\"\n",
      "        }\n",
      "      ],\n",
      "      \"extraInfo\": [\n",
      "        \"×›×œ ×”×¡×œ×˜×™× ××•×’×©×™× ×¢× ×©×ª×™ ×œ×—×× ×™×•×ª\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"×ª×•×¡×¤×•×ª\",\n",
      "      \"dishes\": [\n",
      "        {\n",
      "          \"name\": \"×ª×•×¡×¤×ª ×¨×•×˜×‘ ×¤×™×¦×” ×§×˜× ×” ×œ×¡×œ×˜\",\n",
      "          \"price\": 3\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×©×•×, ××œ×£ ×”××™×™×, ×¦'×™×œ×™ ××ª×•×§\",\n",
      "          \"price\": 1\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×¨×•×˜×‘ ×¤×™×¦×”, ××™× ×™ ×˜×•×¡×˜×¨\",\n",
      "          \"price\": 3\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"××‘×—×¨ ×©×ª×™×” ×§×œ×”\",\n",
      "      \"dishes\": [\n",
      "        {\n",
      "          \"name\": \"×©×ª×™×” 1.5 ×œ×™×˜×¨\",\n",
      "          \"price\": 12\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×©×ª×™×” 0.5 ×œ×™×˜×¨\",\n",
      "          \"price\": 9\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×˜×¨×•×¤×™×ª\",\n",
      "          \"price\": 2\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Input tokens:  1340\n",
      "Output tokens:  1023\n",
      "Total tokens:  2363\n",
      "Stop reason: end_turn\n"
     ]
    }
   ],
   "source": [
    "from llm_util import generate_conversation, get_ocr\n",
    "\n",
    "base_test = {\n",
    "                'model_id' : \"us.anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "                'input_image' : \"./images/pizza-1c.png\",\n",
    "                'instructions_filename' : 'pizza_system_prompt1.txt',\n",
    "                'temperature' : 0\n",
    "                }\n",
    "\n",
    "output = get_ocr(base_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets evaluate (manually)! \n",
    "It looks promising, however a manual diff uncovers some mistakes compared to the ground truth Json. For example instead of ×¨×˜×‘×™× (sauces) it hallucinated ×œ×—×× ×™×•×ª (buns).\n",
    "<img title=\"Diff view\" src=\"./images/pizza diff.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hurray! While far from being perfect, it delivers immediate business value (ğŸ’¸, â±ï¸)!\n",
    "While it's not perfect, we can see immediate business value here, as instead of typing everything from scratch a data entry worker could just review the model's output and fix mistakes. Saving time and $.\n",
    "## Let's proceed with formal evaluation\n",
    "We'll calculate a **similarity score**. A custome function that compares both the json structure, text and numbers values, against a ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: 78.61%\n",
      "\n",
      "Detailed Difference Report:\n",
      "Differences found:\n",
      "  Path: categories[0].dishes[3].description\n",
      "  Type: Missing Key\n",
      "  Expected Value 1: V\n",
      "  Actual Value 2: Not present\n",
      "\n",
      "  Path: categories[0].extraInfo[0]\n",
      "  Type: String Difference\n",
      "  Expected Value 1: ×ª×•×¡×¤×ª ×©×•××©×•× ×‘×§×¦×•×•×ª ×”×¤×™×¦×” 2 â‚ª\n",
      "  Actual Value 2: 100% ×¦×”×•×‘×”\n",
      "\n",
      "  Path: categories[1].dishes[4].description\n",
      "  Type: String Difference\n",
      "  Expected Value 1: ×‘×ª×•×¡×¤×ª ×¦×”×•×‘×”, ××•×¦×¨×œ×” ×•×‘×•×œ×’×¨×™×ª\n",
      "  Actual Value 2: (×‘×ª×•×¡×¤×ª ×’×‘×™× ×”, ××•×¦×¨×œ×” ×•×‘×•×œ×’×¨×™×ª)\n",
      "\n",
      "  Path: categories[2].dishes[1].description\n",
      "  Type: String Difference\n",
      "  Expected Value 1: ×—×¡×”, ××œ×¤×¤×•×Ÿ, ×¢×’×‘× ×™×•×ª ×©×¨×™, ×ª×™×¨×¡, ×–×™×ª×™× ×™×¨×•×§×™× ×•×˜×•× ×”\n",
      "  Actual Value 2: ×—×¡×”, ××œ×¤×¤×•×Ÿ, ×¢×’×‘× ×™×•×ª ×©×¨×™, ×ª×™×¨×¡, ×–×™×ª×™× ×©×—×•×¨×™× ×•×˜×•× ×”\n",
      "\n",
      "  Path: categories[2].extraInfo[0]\n",
      "  Type: String Difference\n",
      "  Expected Value 1: ×›×œ ×”×¡×œ×˜×™× ××•×’×©×™× ×¢× ×©×ª×™ ×¨×˜×‘×™× ×œ×‘×—×™×¨×”\n",
      "  Actual Value 2: ×›×œ ×”×¡×œ×˜×™× ××•×’×©×™× ×¢× ×©××Ÿ ×–×™×ª ×•×œ×™××•×Ÿ ×¡×—×•×˜\n",
      "\n",
      "  Path: categories[3].dishes[0].price\n",
      "  Type: Value Difference\n",
      "  Expected Value 1: 3\n",
      "  Actual Value 2: 2\n",
      "\n",
      "  Path: categories[3].dishes[0].name\n",
      "  Type: String Difference\n",
      "  Expected Value 1: ×ª×•×¡×¤×ª ×‘×™×¦×” ×§×©×” ×œ×¡×œ×˜\n",
      "  Actual Value 2: ×ª×•×¡×¤×ª ×©×™××•×© ×‘×§×¦×•×•×ª ×”×¤×™×¦×”\n",
      "\n",
      "  Path: categories[4].name\n",
      "  Type: String Difference\n",
      "  Expected Value 1: ×¨×˜×‘×™×\n",
      "  Actual Value 2: ×ª×•×¡×¤×•×ª ×œ×¡×œ×˜\n",
      "\n",
      "  Path: categories[4].dishes[1].name\n",
      "  Type: String Difference\n",
      "  Expected Value 1: ×¨×•×˜×‘ ×¤×™×¦×”, ××™× ×™ ×˜×‘×¡×§×•\n",
      "  Actual Value 2: ×¨×•×˜×‘ ×¤×™×¦×”, ××™× ×™ ×˜×•×¡×˜×™×\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json_eval\n",
    "expected = json.load(open('./outputs/pizza_expected.json'))\n",
    "actual = json_eval.extract_json_from_string(output)\n",
    "\n",
    "similarity_score, difference_report = compare_json(expected, actual)\n",
    "print(f\"Similarity score: {similarity_score:.2f}%\")\n",
    "print(\"\\nDetailed Difference Report:\")\n",
    "difference_report.print_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with hallucinations ğŸ˜±\n",
    "Let's discuss detection and resolution of hallucinations:\n",
    "#### Detection\n",
    "If we could accurately detect hallucinations, it could improve the human data entry worker to focus on what to fix. ğŸ”¦\n",
    "#### Resolution\n",
    "Reduce hallucination to improve accuracy. ğŸ“ˆ\n",
    "\n",
    "## Detection strategies\n",
    "When in the wild, i.e., w/o ground truth data:\n",
    "1. Compare outputs over multiple invocations ğŸ”¢ to uncover variations in values at specific json paths (use high ğŸŒ¡ï¸ temperature and different ğŸ“ prompts).\n",
    "2. Ask the LLM for a confidence score  alongside each value (wishful thinking?) âœ° âœ° âœ°\n",
    "\n",
    "<img title=\"detection through multi invocation\" src=\"./images/detection multi invoke.png\" />\n",
    "\n",
    "## Resolution strategies\n",
    "1. Majority vote - pick the common answer from multiple invocations\n",
    "2. Confidence - pick highest probability answer\n",
    "3. Character level inference - Once established detected a suspicious value, we can ask the LLM to spell it out character by character.\n",
    "4. Attention - Cropping the document to smaller sections and invoke per prompt (classic CV for bounding boxes)\n",
    "5. Ensemble of the techniques above\n",
    "6. Fine tuning the LLM on this OCR usecase (fine tuning Claude Haiku currently possible in Amazon Bedrock)\n",
    "\n",
    "### Let's attempt detection and resolution using multiple invocations and majority voting\n",
    "Start with defning 5 different invocations designd to induce different results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\".  # Sonnet 3.5 is far better than 3.0 in this task\n",
    "base_test = {\n",
    "                'model_id' : \"us.anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "                'input_image' : \"./images/pizza-1c.png\",\n",
    "                'instructions_filename' : 'pizza_system_prompt1.txt',\n",
    "                'temperature' : 0\n",
    "        }\n",
    "\n",
    "# variations\n",
    "from copy import deepcopy\n",
    "tests = [deepcopy(base_test) for i in range(5)]\n",
    "tests[0]['temperature'] = 0\n",
    "\n",
    "tests[1]['temperature'] = 0.7\n",
    "\n",
    "tests[2]['temperature'] = 0\n",
    "tests[2]['instructions_filename'] = 'pizza_system_prompt2.txt'\n",
    "\n",
    "tests[3]['temperature'] = 1\n",
    "tests[3]['instructions_filename'] = 'pizza_system_prompt2.txt'\n",
    "\n",
    "tests[4]['temperature'] = 1\n",
    "tests[4]['instructions_filename'] = 'pizza_system_prompt3.txt'\n",
    "\n",
    "def get_outfile_path(idx, t):\n",
    "        return f'./outputs/pizza_actual_' + t['model_id'] + f\"_tempr({t['temperature']})_\" + t['instructions_filename'].replace('.txt', '') + f'_{idx}' + '.json'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating message with model us.anthropic.claude-3-5-sonnet-20240620-v1:0\n",
      "Role: assistant\n",
      "Text: Here's the structured menu information extracted from the provided Hebrew menu image:\n",
      "\n",
      "{\n",
      "  \"categories\": [\n",
      "    {\n",
      "      \"name\": \"×ª×¤×¨×™×˜\",\n",
      "      \"dishes\": [\n",
      "        {\n",
      "          \"name\": \"×¤×™×¦×” ××™×©×™×ª (S)\",\n",
      "          \"price\": 20\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×¤×™×¦×” ××©×¤×—×ª×™×ª (L)\",\n",
      "          \"price\": 29\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×¤×™×¦×” ×¢× ×§×™×ª (XL)\",\n",
      "          \"price\": 49\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"××©×¤×—×ª×™×ª ×˜×‘×¢×•× ×™×ª\",\n",
      "          \"price\": 40\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"××©×¤×—×ª×™×ª ×œ×œ× ×’×œ×•×˜×Ÿ\",\n",
      "          \"price\": 45\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×”××œ×¦×ª ×”×©×£ ×¤×™×¦×” ×™×•×•× ×™×ª\",\n",
      "          \"price\": 49,\n",
      "          \"description\": \"×¢×’×‘× ×™×”,×‘×¦×œ,×–×™×ª×™× ×©×—×•×¨×™×,×‘×•×œ×’×¨×™×ª\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"×ª×•×¡×¤×•×ª\",\n",
      "      \"dishes\": [\n",
      "        {\n",
      "          \"name\": \"×ª×•×¡×¤×ª ×©×™××•×© ×‘×§×¦×•×ª ×”×¤×™×¦×”\",\n",
      "          \"price\": 2\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"×œ×—× ×©×•×\",\n",
      "      \"dishes\": [\n",
      "        {\n",
      "          \"name\": \"×œ×—× ×©×•× ××™×©×™\",\n",
      "          \"price\": 15\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×œ×—× ×©×•× ××™×©×™ ××•×§×¨×\",\n",
      "          \"price\": 18\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×œ×—× ×©×•× ××©×¤×—×ª×™\",\n",
      "          \"price\": 26\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×œ×—× ×©×•× ××©×¤×—×ª×™ ××•×§×¨×\",\n",
      "          \"price\": 33\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×œ×—× ×©×•× ×”×‘×™×ª (L)\",\n",
      "          \"price\": 45,\n",
      "          \"description\": \"×‘×ª×•×¡×¤×ª ×’×‘×™× ×”, ××•×¦×¨×œ×” ×•×‘×•×œ×’×¨×™×ª\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"×¡×œ×˜×™×\",\n",
      "      \"dishes\": [\n",
      "        {\n",
      "          \"name\": \"×¡×œ×˜ ×‘×•×œ×’×¨×™×ª\",\n",
      "          \"price\": 34,\n",
      "          \"description\": \"×—×¡×”, ××œ×¤×¤×•×Ÿ, ×¢×’×‘× ×™×•×ª ×©×¨×™, ×ª×™×¨×¡, ×–×™×ª×™× ×©×—×•×¨×™× ×•×‘×•×œ×’×¨×™×ª\"\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×¡×œ×˜ ×˜×•× ×”\",\n",
      "          \"price\": 34,\n",
      "          \"description\": \"×—×¡×”, ××œ×¤×¤×•×Ÿ, ×¢×’×‘× ×™×•×ª ×©×¨×™, ×ª×™×¨×¡, ×–×™×ª×™× ×™×¨×•×§×™× ×•×˜×•× ×”\"\n",
      "        }\n",
      "      ],\n",
      "      \"extraInfo\": [\n",
      "        \"×›×œ ×”×¡×œ×˜×™× ××•×’×©×™× ×¢× ×©××Ÿ ×–×™×ª ×•×œ×™××•×Ÿ ×œ×‘×—×™×¨×”\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"×ª×•×¡×¤×•×ª ×œ×¡×œ×˜\",\n",
      "      \"dishes\": [\n",
      "        {\n",
      "          \"name\": \"×ª×•×¡×¤×ª ×‘×¦×œ ×§×¦×•×¥ ×œ×¡×œ×˜\",\n",
      "          \"price\": 3\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×©×•×, ××œ×£ ×”××™×™×, ×¦'×™×œ×™ ××ª×•×§\",\n",
      "          \"price\": 1\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×¨×•×˜×‘ ×¤×™×¦×”, ××™× ×™ ×˜×•×¡×˜×¨\",\n",
      "          \"price\": 3\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"××‘×—×¨ ×©×ª×™×” ×§×œ×”\",\n",
      "      \"dishes\": [\n",
      "        {\n",
      "          \"name\": \"×©×ª×™×” 1.5 ×œ×™×˜×¨\",\n",
      "          \"price\": 12\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×©×ª×™×” 0.5 ×œ×™×˜×¨\",\n",
      "          \"price\": 9\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×˜×¨×•×¤×™×ª\",\n",
      "          \"price\": 2\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Input tokens:  1352\n",
      "Output tokens:  1027\n",
      "Total tokens:  2379\n",
      "Stop reason: end_turn\n",
      "Writing output to ./outputs/pizza_actual_us.anthropic.claude-3-5-sonnet-20240620-v1:0_tempr(0)_pizza_system_prompt2_2.json\n",
      "Generating message with model us.anthropic.claude-3-5-sonnet-20240620-v1:0\n",
      "Role: assistant\n",
      "Text: I'll extract the structured menu information from the Hebrew menu image, going from right to left and top to bottom. Here's the JSON structure based on the provided schema:\n",
      "\n",
      "{\n",
      "  \"categories\": [\n",
      "    {\n",
      "      \"name\": \"×ª×¤×¨×™×˜\",\n",
      "      \"dishes\": [\n",
      "        {\n",
      "          \"name\": \"×¤×™×¦×” ××™×©×™×ª (S)\",\n",
      "          \"price\": 20\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×¤×™×¦×” ××©×¤×—×ª×™×ª (L)\",\n",
      "          \"price\": 29\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×¤×™×¦×” ×¢× ×§×™×ª (XL)\",\n",
      "          \"price\": 49\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"××©×¤×—×ª×™×ª ×˜×‘×¢×•× ×™×ª\",\n",
      "          \"price\": 40\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"××©×¤×—×ª×™×ª ×œ×œ× ×’×œ×•×˜×Ÿ\",\n",
      "          \"price\": 45\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×”××œ×¦×ª ×”×©×£ ×¤×™×¦×” ×™×•×•× ×™×ª\",\n",
      "          \"price\": 49,\n",
      "          \"description\": \"×¢×’×‘× ×™×”,×‘×¦×œ,×–×™×ª×™× ×©×—×•×¨×™×,×‘×•×œ×’×¨×™×ª\"\n",
      "        }\n",
      "      ],\n",
      "      \"extraInfo\": [\n",
      "        \"×ª×•×¡×¤×ª ×©×•××©×•× ×‘×§×¦×•×•×ª ×”×¤×™×¦×” 2 â‚ª\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"×¡×œ×˜×™×\",\n",
      "      \"dishes\": [\n",
      "        {\n",
      "          \"name\": \"×¡×œ×˜ ×‘×•×œ×’×¨×™×ª\",\n",
      "          \"price\": 34,\n",
      "          \"description\": \"×—×¡×”, ××œ×¤×¤×•×Ÿ, ×¢×’×‘× ×™×•×ª ×©×¨×™, ×ª×™×¨×¡, ×–×™×ª×™× ×©×—×•×¨×™× ×•×‘×•×œ×’×¨×™×ª\"\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×¡×œ×˜ ×˜×•× ×”\",\n",
      "          \"price\": 34,\n",
      "          \"description\": \"×—×¡×”, ××œ×¤×¤×•×Ÿ, ×¢×’×‘× ×™×•×ª ×©×¨×™, ×ª×™×¨×¡, ×–×™×ª×™× ×™×¨×•×§×™× ×•×˜×•× ×”\"\n",
      "        }\n",
      "      ],\n",
      "      \"extraInfo\": [\n",
      "        \"×›×œ ×”×¡×œ×˜×™× ××•×’×©×™× ×¢× ×¤×™×ª×” ×œ×‘× ×”\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"×ª×•×¡×¤×•×ª\",\n",
      "      \"dishes\": [\n",
      "        {\n",
      "          \"name\": \"×ª×•×¡×¤×ª ×¨×•×˜×‘ ×§×©×” ×œ×¡×œ×˜\",\n",
      "          \"price\": 3\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×©×•×, ××œ×£ ×”××™×™×, ×¦'×™×œ×™ ××ª×•×§\",\n",
      "          \"price\": 1\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×¨×•×˜×‘ ×¤×™×¦×”, ××™× ×™ ×˜×•× ×¡×™×Ÿ\",\n",
      "          \"price\": 3\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"××‘×—×¨ ×©×ª×™×” ×§×œ×”\",\n",
      "      \"dishes\": [\n",
      "        {\n",
      "          \"name\": \"×©×ª×™×” 1.5 ×œ×™×˜×¨\",\n",
      "          \"price\": 12\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×©×ª×™×” 0.5 ×œ×™×˜×¨\",\n",
      "          \"price\": 9\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×˜×¨×•×¤×™×ª\",\n",
      "          \"price\": 2\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"×œ×—× ×©×•×\",\n",
      "      \"dishes\": [\n",
      "        {\n",
      "          \"name\": \"×œ×—× ×©×•× ××™×©×™\",\n",
      "          \"price\": 15\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×œ×—× ×©×•× ××™×©×™ ××•×§×¨×\",\n",
      "          \"price\": 18\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×œ×—× ×©×•× ××©×¤×—×ª×™\",\n",
      "          \"price\": 26\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×œ×—× ×©×•× ××©×¤×—×ª×™ ××•×§×¨×\",\n",
      "          \"price\": 33\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×œ×—× ×©×•× ×”×‘×™×ª (L)\",\n",
      "          \"price\": 45,\n",
      "          \"description\": \"×‘×ª×•×¡×¤×ª ×‘×¦×œ×™×, ××•×¦×¨×œ×” ×•×‘×•×œ×’×¨×™×ª\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Input tokens:  1352\n",
      "Output tokens:  1010\n",
      "Total tokens:  2362\n",
      "Stop reason: end_turn\n",
      "Writing output to ./outputs/pizza_actual_us.anthropic.claude-3-5-sonnet-20240620-v1:0_tempr(1)_pizza_system_prompt2_3.json\n",
      "Generating message with model us.anthropic.claude-3-5-sonnet-20240620-v1:0\n",
      "Role: assistant\n",
      "Text: Here's the extracted menu information in JSON format based on the provided Hebrew menu image:\n",
      "\n",
      "{\n",
      "  \"categories\": [\n",
      "    {\n",
      "      \"name\": \"×ª×¤×¨×™×˜\",\n",
      "      \"dishes\": [\n",
      "        {\n",
      "          \"name\": \"×¤×™×¦×” ××™×©×™×ª (S)\",\n",
      "          \"price\": 20\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×¤×™×¦×” ××©×¤×—×ª×™×ª (L)\",\n",
      "          \"price\": 29\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×¤×™×¦×” ×¢× ×§×™×ª (XL)\",\n",
      "          \"price\": 49\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"××©×¤×—×ª×™×ª ×˜×‘×¢×•× ×™×ª\",\n",
      "          \"price\": 40\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"××©×¤×—×ª×™×ª ×œ×œ× ×’×œ×•×˜×Ÿ\",\n",
      "          \"price\": 45\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×”××œ×¦×ª ×”×©×£ ×¤×™×¦×” ×™×•×•× ×™×ª\",\n",
      "          \"price\": 49,\n",
      "          \"description\": \"×¢×’×‘× ×™×”,×‘×¦×œ,×–×™×ª×™× ×©×—×•×¨×™×,×‘×•×œ×’×¨×™×ª\"\n",
      "        }\n",
      "      ],\n",
      "      \"extraInfo\": [\n",
      "        \"100% ××•×¦×¨×œ×”\",\n",
      "        \"100% ×¦×”×•×‘×”\",\n",
      "        \"×¢××§\",\n",
      "        \"×ª× ×•×‘×”\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"×ª×•×¡×¤×•×ª\",\n",
      "      \"dishes\": [\n",
      "        {\n",
      "          \"name\": \"×ª×•×¡×¤×ª ×©×™××•×© ×‘×§×¦×•×•×ª ×”×¤×™×¦×”\",\n",
      "          \"price\": 2\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"×œ×—× ×©×•×\",\n",
      "      \"dishes\": [\n",
      "        {\n",
      "          \"name\": \"×œ×—× ×©×•× ××™×©×™\",\n",
      "          \"price\": 15\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×œ×—× ×©×•× ××™×©×™ ××•×§×¨×\",\n",
      "          \"price\": 18\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×œ×—× ×©×•× ××©×¤×—×ª×™\",\n",
      "          \"price\": 26\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×œ×—× ×©×•× ××©×¤×—×ª×™ ××•×§×¨×\",\n",
      "          \"price\": 33\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×œ×—× ×©×•× ×”×‘×™×ª (L)\",\n",
      "          \"price\": 45,\n",
      "          \"description\": \"(×‘×ª×•×¡×¤×ª ×’×‘×™× ×”, ××•×¦×¨×œ×” ×•×‘×•×œ×’×¨×™×ª)\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"×¡×œ×˜×™×\",\n",
      "      \"dishes\": [\n",
      "        {\n",
      "          \"name\": \"×¡×œ×˜ ×‘×•×œ×’×¨×™×ª\",\n",
      "          \"price\": 34,\n",
      "          \"description\": \"×—×¡×”, ××œ×¤×¤×•×Ÿ, ×¢×’×‘× ×™×•×ª ×©×¨×™, ×ª×™×¨×¡, ×–×™×ª×™× ×©×—×•×¨×™× ×•×‘×•×œ×’×¨×™×ª\"\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×¡×œ×˜ ×˜×•× ×”\",\n",
      "          \"price\": 34,\n",
      "          \"description\": \"×—×¡×”, ××œ×¤×¤×•×Ÿ, ×¢×’×‘× ×™×•×ª ×©×¨×™, ×ª×™×¨×¡, ×–×™×ª×™× ×©×—×•×¨×™× ×•×˜×•× ×”\"\n",
      "        }\n",
      "      ],\n",
      "      \"extraInfo\": [\n",
      "        \"×›×œ ×”×¡×œ×˜×™× ××•×’×©×™× ×¢× ×©××Ÿ ×–×™×ª ×•×œ×™××•×Ÿ ×¡×—×•×˜\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"×ª×•×¡×¤×•×ª ×œ×¡×œ×˜\",\n",
      "      \"dishes\": [\n",
      "        {\n",
      "          \"name\": \"×ª×•×¡×¤×ª ×‘×¦×œ ×§×©×•×˜ ×œ×¡×œ×˜\",\n",
      "          \"price\": 3\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×©×•×, ××œ×£ ×”××™×™×, ×¦'×™×œ×™ ××ª×•×§\",\n",
      "          \"price\": 1\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×¨×•×˜×‘ ×¤×™×¦×”, ××™× ×™ ×˜×•×¡×˜×™×\",\n",
      "          \"price\": 3\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"××‘×—×¨ ×©×ª×™×” ×§×œ×”\",\n",
      "      \"dishes\": [\n",
      "        {\n",
      "          \"name\": \"×©×ª×™×” 1.5 ×œ×™×˜×¨\",\n",
      "          \"price\": 12\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×©×ª×™×” 0.5 ×œ×™×˜×¨\",\n",
      "          \"price\": 9\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"×˜×¨×•×¤×™×ª\",\n",
      "          \"price\": 2\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Input tokens:  1471\n",
      "Output tokens:  1074\n",
      "Total tokens:  2545\n",
      "Stop reason: end_turn\n",
      "Writing output to ./outputs/pizza_actual_us.anthropic.claude-3-5-sonnet-20240620-v1:0_tempr(1)_pizza_system_prompt3_4.json\n"
     ]
    }
   ],
   "source": [
    "for idx,test in enumerate(tests): # IMPROVE: can run in parallel\n",
    "        outfile_path = get_outfile_path(idx, test)\n",
    "        output = get_ocr(test)\n",
    "        print(f'Writing output to {outfile_path}')\n",
    "        open(outfile_path, 'w').write(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing tests with ground truth data\n",
    "We can see that we get different outputs with different levels of accuracy, hopefully these differences will largely intersect with the hallucinations we want to detect and resolve.\n",
    "Comparing with similarity with ground truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test(0)<>GT - similarity: 86.98%\n",
      "Test(1)<>GT - similarity: 81.33%\n",
      "Test(2)<>GT - similarity: 78.96%\n",
      "Test(3)<>GT - similarity: 88.56%\n",
      "Test(4)<>GT - similarity: 78.61%\n",
      "Average Similarity: 82.89%\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for idx,t in enumerate(tests):\n",
    "    # load expected and actual output\n",
    "    expected = json.load(open('./outputs/pizza_expected.json'))\n",
    "    actual_output = open(get_outfile_path(idx, t), \"r\").read()\n",
    "    actual = json_eval.extract_json_from_string(actual_output)\n",
    "    \n",
    "    similarity_score, difference_report = compare_json(expected, actual)\n",
    "    scores.append(similarity_score)\n",
    "    print(f\"Test({idx})<>GT - similarity: {similarity_score:.2f}%\")\n",
    "\n",
    "invocations_avg_similarity = sum(scores)/len(scores)\n",
    "print(f\"Average Similarity: {invocations_avg_similarity:.2f}%\") # average similary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare all tests outputs to invocation[0] output\n",
    "Let's see how similar are the different results to results of invocation(0). We can see they are 85%-90% similar, so might be able to use this to our advantage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test(0)<>Test(0) - Similarity: 100.00%\n",
      "Test(1)<>Test(0) - Similarity: 90.34%\n",
      "Test(2)<>Test(0) - Similarity: 85.09%\n",
      "Test(3)<>Test(0) - Similarity: 94.56%\n",
      "Test(4)<>Test(0) - Similarity: 85.13%\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "expected_output = open(get_outfile_path(0, tests[0]), \"r\").read()\n",
    "expected = json_eval.extract_json_from_string(expected_output)\n",
    "for idx,t in enumerate(tests):\n",
    "    actual_output = open(get_outfile_path(idx, t), \"r\").read()\n",
    "    actual = json_eval.extract_json_from_string(actual_output)\n",
    "    similarity_score, difference_report = compare_json(expected, actual)\n",
    "    print(f\"Test({idx})<>Test(0) - Similarity: {similarity_score:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate majority vote per all possible variations across all invocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let's review different values for each difference:\n",
      "{'categories[0].extraInfo[0]': {'path': 'categories[0].extraInfo[0]',\n",
      "                                'type': 'String Difference',\n",
      "                                'values': {'100% ×¦×”×•×‘×”': 2,\n",
      "                                           '100% ×¦×”×•×‘×” ×¢××§': 1,\n",
      "                                           '×ª×•×¡×¤×ª ×©×•××©×•× ×‘×§×¦×•×•×ª ×”×¤×™×¦×” 2 â‚ª': 3}},\n",
      " 'categories[1].dishes[4].description': {'path': 'categories[1].dishes[4].description',\n",
      "                                         'type': 'String Difference',\n",
      "                                         'values': {'(×‘×ª×•×¡×¤×ª ×’×‘×™× ×”, ××•×¦×¨×œ×” ×•×‘×•×œ×’×¨×™×ª)': 2,\n",
      "                                                    '(×‘×ª×•×¡×¤×ª ×¢×’×‘× ×™×”, ××•×¦×¨×œ×” ×•×‘×•×œ×’×¨×™×ª)': 1,\n",
      "                                                    '×‘×ª×•×¡×¤×ª ×‘×¦×œ×™×, ××•×¦×¨×œ×” ×•×‘×•×œ×’×¨×™×ª': 2,\n",
      "                                                    '×‘×ª×•×¡×¤×ª ×’×‘×™× ×”, ××•×¦×¨×œ×” ×•×‘×•×œ×’×¨×™×ª': 2,\n",
      "                                                    '×‘×ª×•×¡×¤×ª ×–×¢×ª×¨, ××•×¦×¨×œ×” ×•×‘×•×œ×’×¨×™×ª': 1}},\n",
      " 'categories[2].dishes[1].description': {'path': 'categories[2].dishes[1].description',\n",
      "                                         'type': 'String Difference',\n",
      "                                         'values': {'×—×¡×”, ××œ×¤×¤×•×Ÿ, ×¢×’×‘× ×™×•×ª ×©×¨×™, ×ª×™×¨×¡, ×–×™×ª×™× ×™×¨×•×§×™× ×•×˜×•× ×”': 4,\n",
      "                                                    '×—×¡×”, ××œ×¤×¤×•×Ÿ, ×¢×’×‘× ×™×•×ª ×©×¨×™, ×ª×™×¨×¡, ×–×™×ª×™× ×©×—×•×¨×™× ×•×˜×•× ×”': 1}},\n",
      " 'categories[2].extraInfo[0]': {'path': 'categories[2].extraInfo[0]',\n",
      "                                'type': 'String Difference',\n",
      "                                'values': {'×›×œ ×”×¡×œ×˜×™× ××•×’×©×™× ×¢× ×¤×™×ª×” ×œ×‘× ×”': 2,\n",
      "                                           '×›×œ ×”×¡×œ×˜×™× ××•×’×©×™× ×¢× ×©××Ÿ ×–×™×ª ×•×œ×™××•×Ÿ ×œ×‘×—×™×¨×”': 2,\n",
      "                                           '×›×œ ×”×¡×œ×˜×™× ××•×’×©×™× ×¢× ×©××Ÿ ×–×™×ª ×•×œ×™××•×Ÿ ×œ×¦×“×': 1,\n",
      "                                           '×›×œ ×”×¡×œ×˜×™× ××•×’×©×™× ×¢× ×©××Ÿ ×–×™×ª ×•×œ×™××•×Ÿ ×¡×—×•×˜': 2}},\n",
      " 'categories[3].dishes[0].name': {'path': 'categories[3].dishes[0].name',\n",
      "                                  'type': 'String Difference',\n",
      "                                  'values': {\"×©×•×, ××œ×£ ×”××™×™×, ×¦'×™×œ×™ ××ª×•×§\": 4,\n",
      "                                             \"×ª×•×¡×¤×ª ×¨×•×˜×‘ ×¦'×™×œ×™\": 1}},\n",
      " 'categories[3].dishes[1].name': {'path': 'categories[3].dishes[1].name',\n",
      "                                  'type': 'String Difference',\n",
      "                                  'values': {'×ª×•×¡×¤×ª ×‘×¦×œ ×§×¦×•×¥ ×œ×¡×œ×˜': 2,\n",
      "                                             '×ª×•×¡×¤×ª ×‘×¦×œ ×§×©×•×˜ ×œ×¡×œ×˜': 2,\n",
      "                                             '×ª×•×¡×¤×ª ×¨×•×˜×‘ ×§×©×” ×œ×¡×œ×˜': 2,\n",
      "                                             '×ª×•×¡×¤×ª ×¨×•×˜×‘ ×§×©×™×• ×œ×¡×œ×˜': 1}},\n",
      " 'categories[3].dishes[3].name': {'path': 'categories[3].dishes[3].name',\n",
      "                                  'type': 'String Difference',\n",
      "                                  'values': {'×¨×•×˜×‘ ×¤×™×¦×”, ××™× ×™ ×˜×•× ×¡×™×Ÿ': 1,\n",
      "                                             '×¨×•×˜×‘ ×¤×™×¦×”, ××™× ×™ ×˜×•×¡×˜×™×': 2,\n",
      "                                             '×¨×•×˜×‘ ×¤×™×¦×”, ××™× ×™ ×˜×•×¡×˜×¨': 3}},\n",
      " 'categories[3].name': {'path': 'categories[3].name',\n",
      "                        'type': 'String Difference',\n",
      "                        'values': {'×ª×•×¡×¤×•×ª': 3, '×ª×•×¡×¤×•×ª ×œ×¡×œ×˜': 2}}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(depth=5)\n",
    "print(\"let's review different values for each difference:\")\n",
    "all_differences = {}\n",
    "num_tests = len(tests)\n",
    "for idx,t in enumerate(tests):\n",
    "    if idx == 0: continue\n",
    "    actual_output = open(get_outfile_path(idx, t), \"r\").read()\n",
    "    actual = json_eval.extract_json_from_string(actual_output)\n",
    "    \n",
    "    similarity_score, difference_report = compare_json(expected, actual)\n",
    "    for i, diff in enumerate(difference_report.differences):\n",
    "        path_diff = all_differences.get(diff['path'])\n",
    "        if diff['type'] == 'Missing Key': continue # not dealing with these now, only with value differences\n",
    "        if path_diff is None:\n",
    "            values = {  diff['expected value'] : num_tests-1, # start assuming it's the only difference we'll encounter\n",
    "                        diff['actual value'] : 1} \n",
    "            path_diff = {'path' : diff['path'],\n",
    "                         'type' : diff['type'],\n",
    "                         'values' : values}\n",
    "            all_differences[diff['path']] = path_diff\n",
    "        else:\n",
    "            count = path_diff['values'].get(diff['actual value']) or 1\n",
    "            path_diff['values'][diff['actual value']] = count + 1\n",
    "            path_diff['values'][diff['expected value']] += -1\n",
    "\n",
    "pp.pprint(all_differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure accuracy of majority vote output against ground truth\n",
    "We'll update invocation(0) output with the mojority voted values for all value differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_test<>GT - Similarity: 87.40%\n",
      "Keep in mind that the Average Similarity is only: 82.89%\n",
      "We achieved an uplift of 4.51% using majority vote resolution\n"
     ]
    }
   ],
   "source": [
    "test0_output = open(get_outfile_path(0, tests[0]), \"r\").read()\n",
    "test0 = json_eval.extract_json_from_string(test0_output)\n",
    "\n",
    "import copy\n",
    "avg_actual_obj = json_eval.update_json_with_highest_values(copy.deepcopy(test0), all_differences)\n",
    "\n",
    "expected = json.load(open('./outputs/pizza_expected.json'))\n",
    "similarity_score, difference_report = compare_json(expected, avg_actual_obj)\n",
    "print(f\"avg_test<>GT - Similarity: {similarity_score:.2f}%\")\n",
    "print(f\"Keep in mind that the Average Similarity is only: {invocations_avg_similarity:.2f}%\")\n",
    "uplift = similarity_score - invocations_avg_similarity\n",
    "print(f\"We achieved an uplift of {uplift:.2f}% using majority vote resolution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "1. It's still early days for vision tasks, and it's robustness needs to improve\n",
    "2. Until this happens being able to \"Reflect\" and fix halucinations can greatly help the end result\n",
    "3. The same techniques can be used with Agents where small inaccuracies causes drift in multi-steps computations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "1. ğŸ—’ You can find this notebook in the Github repo here: [https://github.com/gilinachum/LLM-OCR-Evaluation/blob/main/main.ipynb](https://github.com/gilinachum/LLM-OCR-Evaluation/blob/main/main.ipynb).\n",
    "2. ğŸï¸ See a recorded deep dive in the AWS Israel Hebrew YouTube: [https://bit.ly/aws-hebrew-youtube](https://bit.ly/aws-hebrew-youtube)\n",
    "<img href>\n",
    "3. ğŸ“¢ WE'RE HIRING!\n",
    "<img title=\"ğŸ“¢ WE'RE HIRING!\" src=\"./images/we are hiring.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: 81.66%\n",
      "\n",
      "Detailed Difference Report:\n",
      "Differences found:\n",
      "  Path: categories[0].dishes[3].description\n",
      "  Type: Missing Key\n",
      "  Value 1: V\n",
      "  Value 2: Not present\n",
      "\n",
      "  Path: categories[0].dishes[5].name\n",
      "  Type: String Difference\n",
      "  Value 1: ×”××œ×¦×ª ×”×©×£ ×¤×™×¦×” ×™×•×•× ×™×ª\n",
      "  Value 2: ×”××œ×¦×ª ×”×©×£ ×¤×™×¦×” ×™×•×•× ×™×ª×ª\n",
      "\n",
      "  Path: categories[0].extraInfo[0]\n",
      "  Type: String Difference\n",
      "  Value 1: ×ª×•×¡×¤×ª ×©×™××•×©×™× ×‘×§×¦×•×•×ª ×”×¤×™×¦×” 2 â‚ª\n",
      "  Value 2: 100% ×’×‘×™× ×” ×¢××§\n",
      "\n",
      "  Path: categories[1].extraInfo[0]\n",
      "  Type: String Difference\n",
      "  Value 1: ×›×œ ×”×¡×œ×˜×™× ××’×™×¢×™× ×¢× ×©×ª×™ ×œ×—×× ×™×•×ª ×œ×‘×—×™×¨×”\n",
      "  Value 2: ×›×œ ×”×¡×œ×˜×™× ××•×’×©×™× ×¢× ×¤×™×ª×” ×œ×‘× ×”\n",
      "\n",
      "  Path: categories[3].name\n",
      "  Type: String Difference\n",
      "  Value 1: ×¨×˜×‘×™×\n",
      "  Value 2: ×ª×•×¡×¤×•×ª\n",
      "\n",
      "  Path: categories[3].dishes[1].name\n",
      "  Type: String Difference\n",
      "  Value 1: ×¨×•×˜×‘ ×¤×™×¦×”, ××™× ×™ ×¡×˜×™×™×§\n",
      "  Value 2: ×¨×•×˜×‘ ×¤×™×¦×”, ××™× ×™ ×˜×•×¡×˜×¨\n",
      "\n",
      "  Path: categories[4].dishes[4].name\n",
      "  Type: String Difference\n",
      "  Value 1: ×œ×—× ×©×•× ×¢× ×§ (L)\n",
      "  Value 2: ×œ×—× ×©×•× ×”×‘×™×ª (L)\n",
      "\n",
      "  Path: categories[4].dishes[4].description\n",
      "  Type: String Difference\n",
      "  Value 1: ×‘×ª×•×¡×¤×ª ×–×™×ª×™×, ××•×¦×¨×œ×” ×•×‘×•×œ×’×¨×™×ª\n",
      "  Value 2: (×‘×ª×•×¡×¤×ª ×’×‘×™× ×”, ××•×¦×¨×œ×” ×•×‘×•×œ×’×¨×™×ª)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load json from outputs/groundtruth1.json\n",
    "expected = json.load(open('./outputs/pizza_expected.json'))\n",
    "actual = json.load(open('./outputs/pizza_actual.json'))\n",
    "actual = actual_json\n",
    "\n",
    "similarity_score, difference_report = compare_json(expected, actual)\n",
    "print(f\"Similarity score: {similarity_score:.2f}%\")\n",
    "print(\"\\nDetailed Difference Report:\")\n",
    "difference_report.print_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: 77.76%\n",
      "\n",
      "Detailed Difference Report:\n",
      "Differences found:\n",
      "  Path: age\n",
      "  Type: Value Difference\n",
      "  Value 1: 30\n",
      "  Value 2: 31\n",
      "\n",
      "  Path: name\n",
      "  Type: String Difference\n",
      "  Value 1: John\n",
      "  Value 2: Jon\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "import json\n",
    "json1 = json.loads('{\"name\": \"John\", \"age\": 30, \"city\": \"New York\", \"hobbies\": [\"reading\", \"swimming\"]}')\n",
    "json2 = json.loads('{\"name\": \"Jon\", \"age\": 31, \"city\": \"New York\", \"hobbies\": [\"reading\", \"running\"]}')\n",
    "\n",
    "from json_eval import compare_json\n",
    "\n",
    "similarity_score, difference_report = compare_json(json1, json2)\n",
    "print(f\"Similarity score: {similarity_score:.2f}%\")\n",
    "print(\"\\nDetailed Difference Report:\")\n",
    "difference_report.print_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: 35.73%\n",
      "\n",
      "Detailed Difference Report:\n",
      "Differences found:\n",
      "  Path: categories[0].extraInfo[0]\n",
      "  Type: String Difference\n",
      "  Value 1: ×ª×•×¡×¤×ª ×©×™××•×©×™× ×‘×§×¦×•×•×ª ×”×¤×™×¦×” 2 â‚ª\n",
      "  Value 2: ×ª×•×¡×¤×ª ×‘×™×¦×” ×§×©×” ×œ×¡×œ×˜ 3 ×©\"×—\n",
      "\n",
      "  Path: categories[0].dishes[0].price\n",
      "  Type: Value Difference\n",
      "  Value 1: 20\n",
      "  Value 2: 34\n",
      "\n",
      "  Path: categories[0].dishes[0].name\n",
      "  Type: String Difference\n",
      "  Value 1: ×¤×™×¦×” ××™×©×™×ª (S)\n",
      "  Value 2: ×¡×œ×˜ ×˜×•×¨×§×™\n",
      "\n",
      "  Path: categories[0].dishes[0].description\n",
      "  Type: Missing Key\n",
      "  Value 1: Not present\n",
      "  Value 2: ×—×¡×”, ××œ×¤×¤×•×Ÿ, ×¢×’×‘× ×™×” ×©×¨×™, ×—×¦×™×œ×™× ×•×–×™×ª×™× ×©×¨×•×™×™×\n",
      "\n",
      "  Path: categories[0].dishes[1].price\n",
      "  Type: Value Difference\n",
      "  Value 1: 29\n",
      "  Value 2: 34\n",
      "\n",
      "  Path: categories[0].dishes[1].name\n",
      "  Type: String Difference\n",
      "  Value 1: ×¤×™×¦×” ××©×¤×—×ª×™×ª (L)\n",
      "  Value 2: ×¡×œ×˜ ×‘×’×¨×•×–×™×ª\n",
      "\n",
      "  Path: categories[0].dishes[1].description\n",
      "  Type: Missing Key\n",
      "  Value 1: Not present\n",
      "  Value 2: ×—×¡×”, ××œ×¤×¤×•×Ÿ, ×¢×’×‘× ×™×” ×©×¨×™, ×—×¦×™×œ×™× ×•×‘×™×¦×™× ×©×¨×•×™×™×\n",
      "\n",
      "  Path: categories[0].dishes[2].price\n",
      "  Type: Value Difference\n",
      "  Value 1: 49\n",
      "  Value 2: 34\n",
      "\n",
      "  Path: categories[0].dishes[2].name\n",
      "  Type: String Difference\n",
      "  Value 1: ×¤×™×¦×” ×¢× ×§×™×ª (XL)\n",
      "  Value 2: ×¡×œ×˜ ×˜×•×¨×§×™\n",
      "\n",
      "  Path: categories[0].dishes[2].description\n",
      "  Type: Missing Key\n",
      "  Value 1: Not present\n",
      "  Value 2: ×—×¡×”, ××œ×¤×¤×•×Ÿ, ×¢×’×‘× ×™×” ×©×¨×™, ×—×¦×™×œ×™× ×•×–×™×ª×™× ×©×¨×•×™×™×\n",
      "\n",
      "  Path: categories[0].dishes[3].price\n",
      "  Type: Value Difference\n",
      "  Value 1: 40\n",
      "  Value 2: 34\n",
      "\n",
      "  Path: categories[0].dishes[3].name\n",
      "  Type: String Difference\n",
      "  Value 1: ××©×¤×—×ª×™×ª ×˜×‘×¢×•× ×™×ª\n",
      "  Value 2: ×¡×œ×˜ ×‘×’×¨×•×–×™×ª\n",
      "\n",
      "  Path: categories[0].dishes[3].description\n",
      "  Type: String Difference\n",
      "  Value 1: V\n",
      "  Value 2: ×—×¡×”, ××œ×¤×¤×•×Ÿ, ×¢×’×‘× ×™×” ×©×¨×™, ×—×¦×™×œ×™× ×•×‘×™×¦×™× ×©×¨×•×™×™×\n",
      "\n",
      "  Path: categories[0].dishes[4].price\n",
      "  Type: Value Difference\n",
      "  Value 1: 45\n",
      "  Value 2: 34\n",
      "\n",
      "  Path: categories[0].dishes[4].name\n",
      "  Type: String Difference\n",
      "  Value 1: ××©×¤×—×ª×™×ª ×œ×œ× ×’×œ×•×˜×Ÿ\n",
      "  Value 2: ×¡×œ×˜ ×‘×’×¨×•×–×™×ª\n",
      "\n",
      "  Path: categories[0].dishes[4].description\n",
      "  Type: Missing Key\n",
      "  Value 1: Not present\n",
      "  Value 2: ×—×¡×”, ××œ×¤×¤×•×Ÿ, ×¢×’×‘× ×™×” ×©×¨×™, ×—×¦×™×œ×™× ×•×‘×™×¦×™× ×©×¨×•×™×™×\n",
      "\n",
      "  Path: categories[0].dishes[5].price\n",
      "  Type: Value Difference\n",
      "  Value 1: 49\n",
      "  Value 2: 34\n",
      "\n",
      "  Path: categories[0].dishes[5].name\n",
      "  Type: String Difference\n",
      "  Value 1: ×”××œ×¦×ª ×”×©×£ ×¤×™×¦×” ×™×•×•× ×™×ª\n",
      "  Value 2: ×¡×œ×˜ ×‘×’×¨×•×–×™×ª\n",
      "\n",
      "  Path: categories[0].dishes[5].description\n",
      "  Type: String Difference\n",
      "  Value 1: ×¢×’×‘× ×™×”,×‘×¦×œ,×–×™×ª×™× ×©×—×•×¨×™×,×‘×•×œ×’×¨×™×ª\n",
      "  Value 2: ×—×¡×”, ××œ×¤×¤×•×Ÿ, ×¢×’×‘× ×™×” ×©×¨×™, ×—×¦×™×œ×™× ×•×‘×™×¦×™× ×©×¨×•×™×™×\n",
      "\n",
      "  Path: categories[1].extraInfo[0]\n",
      "  Type: String Difference\n",
      "  Value 1: ×›×œ ×”×¡×œ×˜×™× ××’×™×¢×™× ×¢× ×©×ª×™ ×œ×—×× ×™×•×ª ×œ×‘×—×™×¨×”\n",
      "  Value 2: ×ª×•×¡×¤×ª ×‘×™×¦×” ×§×©×” ×œ×¡×œ×˜ 3 ×©\"×—\n",
      "\n",
      "  Path: categories[1].dishes[0].name\n",
      "  Type: String Difference\n",
      "  Value 1: ×¡×œ×˜ ×‘×•×œ×’×¨×™×ª\n",
      "  Value 2: ×¡×œ×˜ ×‘×’×¨×•×–×™×ª\n",
      "\n",
      "  Path: categories[1].dishes[0].description\n",
      "  Type: String Difference\n",
      "  Value 1: ×—×¡×”, ××œ×¤×¤×•×Ÿ, ×¢×’×‘× ×™×•×ª ×©×¨×™, ×ª×™×¨×¡, ×–×™×ª×™× ×©×—×•×¨×™× ×•×‘×•×œ×’×¨×™×ª\n",
      "  Value 2: ×—×¡×”, ××œ×¤×¤×•×Ÿ, ×¢×’×‘× ×™×” ×©×¨×™, ×—×¦×™×œ×™× ×•×‘×™×¦×™× ×©×¨×•×™×™×\n",
      "\n",
      "  Path: categories[1].dishes[1].name\n",
      "  Type: String Difference\n",
      "  Value 1: ×¡×œ×˜ ×˜×•× ×”\n",
      "  Value 2: ×¡×œ×˜ ×˜×•×¨×§×™\n",
      "\n",
      "  Path: categories[1].dishes[1].description\n",
      "  Type: String Difference\n",
      "  Value 1: ×—×¡×”, ××œ×¤×¤×•×Ÿ, ×¢×’×‘× ×™×•×ª ×©×¨×™, ×ª×™×¨×¡, ×–×™×ª×™× ×™×¨×•×§×™× ×•×˜×•× ×”\n",
      "  Value 2: ×—×¡×”, ××œ×¤×¤×•×Ÿ, ×¢×’×‘× ×™×” ×©×¨×™, ×—×¦×™×œ×™× ×•×–×™×ª×™× ×©×¨×•×™×™×\n",
      "\n",
      "  Path: categories[1].name\n",
      "  Type: String Difference\n",
      "  Value 1: ×¡×œ×˜×™×\n",
      "  Value 2: ×ª×¤×¨×™×˜\n",
      "\n",
      "  Path: categories[2].extraInfo\n",
      "  Type: Missing Key\n",
      "  Value 1: Not present\n",
      "  Value 2: ['×ª×•×¡×¤×ª ×‘×™×¦×” ×§×©×” ×œ×¡×œ×˜ 3 ×©\"×—', '×©×•×, ××’×•×–×™ ××œ×š, ×—××•×¦×™× 1 ×©\"×—', '×–×™×ª×™×, ×‘×™×¦×”, ××™×¥ ×œ×™××•×Ÿ 3 ×©\"×—']\n",
      "\n",
      "  Path: categories[2].dishes[0].price\n",
      "  Type: Value Difference\n",
      "  Value 1: 3\n",
      "  Value 2: 34\n",
      "\n",
      "  Path: categories[2].dishes[0].name\n",
      "  Type: String Difference\n",
      "  Value 1: ×ª×•×¡×¤×ª ×‘×™×¦×” ×§×©×” ×œ×¡×œ×˜\n",
      "  Value 2: ×¡×œ×˜ ×‘×’×¨×•×–×™×ª\n",
      "\n",
      "  Path: categories[2].dishes[0].description\n",
      "  Type: Missing Key\n",
      "  Value 1: Not present\n",
      "  Value 2: ×—×¡×”, ××œ×¤×¤×•×Ÿ, ×¢×’×‘× ×™×” ×©×¨×™, ×—×¦×™×œ×™× ×•×‘×™×¦×™× ×©×¨×•×™×™×\n",
      "\n",
      "  Path: categories[2].name\n",
      "  Type: String Difference\n",
      "  Value 1: ×ª×•×¡×¤×•×ª\n",
      "  Value 2: ×ª×¤×¨×™×˜\n",
      "\n",
      "  Path: categories[3].extraInfo\n",
      "  Type: Missing Key\n",
      "  Value 1: Not present\n",
      "  Value 2: ['×ª×•×¡×¤×ª ×‘×™×¦×” ×§×©×” ×œ×¡×œ×˜ 3 ×©\"×—', '×©×•×, ××’×•×–×™ ××œ×š, ×—××•×¦×™× 1 ×©\"×—', '×–×™×ª×™×, ×‘×™×¦×”, ××™×¥ ×œ×™××•×Ÿ 3 ×©\"×—']\n",
      "\n",
      "  Path: categories[3].dishes[0].price\n",
      "  Type: Value Difference\n",
      "  Value 1: 1\n",
      "  Value 2: 34\n",
      "\n",
      "  Path: categories[3].dishes[0].name\n",
      "  Type: String Difference\n",
      "  Value 1: ×©×•×, ××œ×£ ×”××™×™×, ×¦'×™×œ×™ ××ª×•×§\n",
      "  Value 2: ×¡×œ×˜ ×‘×’×¨×•×–×™×ª\n",
      "\n",
      "  Path: categories[3].dishes[0].description\n",
      "  Type: Missing Key\n",
      "  Value 1: Not present\n",
      "  Value 2: ×—×¡×”, ××œ×¤×¤×•×Ÿ, ×¢×’×‘× ×™×” ×©×¨×™, ×—×¦×™×œ×™× ×•×‘×™×¦×™× ×©×¨×•×™×™×\n",
      "\n",
      "  Path: categories[3].dishes[1].price\n",
      "  Type: Value Difference\n",
      "  Value 1: 3\n",
      "  Value 2: 34\n",
      "\n",
      "  Path: categories[3].dishes[1].name\n",
      "  Type: String Difference\n",
      "  Value 1: ×¨×•×˜×‘ ×¤×™×¦×”, ××™× ×™ ×¡×˜×™×™×§\n",
      "  Value 2: ×¡×œ×˜ ×‘×’×¨×•×–×™×ª\n",
      "\n",
      "  Path: categories[3].dishes[1].description\n",
      "  Type: Missing Key\n",
      "  Value 1: Not present\n",
      "  Value 2: ×—×¡×”, ××œ×¤×¤×•×Ÿ, ×¢×’×‘× ×™×” ×©×¨×™, ×—×¦×™×œ×™× ×•×‘×™×¦×™× ×©×¨×•×™×™×\n",
      "\n",
      "  Path: categories[3].name\n",
      "  Type: String Difference\n",
      "  Value 1: ×¨×˜×‘×™×\n",
      "  Value 2: ×ª×¤×¨×™×˜\n",
      "\n",
      "  Path: categories[4].dishes[0].name\n",
      "  Type: String Difference\n",
      "  Value 1: ×œ×—× ×©×•× ××™×©×™\n",
      "  Value 2: ×œ×—× ×©×•× ××•×§×¨×\n",
      "\n",
      "  Path: categories[4].dishes[0].price\n",
      "  Type: Value Difference\n",
      "  Value 1: 15\n",
      "  Value 2: 18\n",
      "\n",
      "  Path: categories[4].dishes[1].name\n",
      "  Type: String Difference\n",
      "  Value 1: ×œ×—× ×©×•× ××™×©×™ ××•×§×¨×\n",
      "  Value 2: ×œ×—× ×©×•× ××•×§×¨×\n",
      "\n",
      "  Path: categories[4].dishes[2].name\n",
      "  Type: String Difference\n",
      "  Value 1: ×œ×—× ×©×•× ××©×¤×—×ª×™\n",
      "  Value 2: ×œ×—× ×©×•× ××©×•×§×©×§\n",
      "\n",
      "  Path: categories[4].dishes[3].name\n",
      "  Type: String Difference\n",
      "  Value 1: ×œ×—× ×©×•× ××©×¤×—×ª×™ ××•×§×¨×\n",
      "  Value 2: ×œ×—× ×©×•× ××©×•×§×©×§ ××•×§×¨×\n",
      "\n",
      "  Path: categories[4].dishes[4].name\n",
      "  Type: String Difference\n",
      "  Value 1: ×œ×—× ×©×•× ×¢× ×§ (L)\n",
      "  Value 2: ×œ×—× ×—×¨×™×£ (L)\n",
      "\n",
      "  Path: categories[4].dishes[4].description\n",
      "  Type: String Difference\n",
      "  Value 1: ×‘×ª×•×¡×¤×ª ×–×™×ª×™×, ××•×¦×¨×œ×” ×•×‘×•×œ×’×¨×™×ª\n",
      "  Value 2: (×ª×•×¡×¤×ª ××‘×•×§×“×• ××•×’×‘×œ×ª ×•×‘×ª×•×¡×¤×ª ×ª×©×œ×•×)\n",
      "\n",
      "  Path: categories[4].name\n",
      "  Type: String Difference\n",
      "  Value 1: ×œ×—× ×©×•×\n",
      "  Value 2: ×œ×—× ×©×•× ××©\"×™\n",
      "\n",
      "  Path: categories[5].dishes[0].name\n",
      "  Type: Type Mismatch\n",
      "  Value 1: str\n",
      "  Value 2: NoneType\n",
      "\n",
      "  Path: categories[5].dishes[0].price\n",
      "  Type: Value Difference\n",
      "  Value 1: 12\n",
      "  Value 2: 15\n",
      "\n",
      "  Path: categories[5].dishes[1].name\n",
      "  Type: Type Mismatch\n",
      "  Value 1: str\n",
      "  Value 2: NoneType\n",
      "\n",
      "  Path: categories[5].dishes[1].price\n",
      "  Type: Value Difference\n",
      "  Value 1: 9\n",
      "  Value 2: 15\n",
      "\n",
      "  Path: categories[5].dishes[2].name\n",
      "  Type: Type Mismatch\n",
      "  Value 1: str\n",
      "  Value 2: NoneType\n",
      "\n",
      "  Path: categories[5].dishes[2].price\n",
      "  Type: Value Difference\n",
      "  Value 1: 2\n",
      "  Value 2: 15\n",
      "\n",
      "  Path: categories[5].name\n",
      "  Type: String Difference\n",
      "  Value 1: ××‘×—×¨ ×©×ª×™×” ×§×œ×”\n",
      "  Value 2: ×œ×—× ×©×•× ××©\"×™\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load json from outputs/groundtruth1.json\n",
    "expected = json.load(open('./outputs/pizza_expected.json'))\n",
    "actual = json.load(open('./outputs/pizza_actual.json'))\n",
    "actual = json.load(open(output_filename_fullpath))\n",
    "\n",
    "similarity_score, difference_report = compare_json(expected, actual)\n",
    "print(f\"Similarity score: {similarity_score:.2f}%\")\n",
    "print(\"\\nDetailed Difference Report:\")\n",
    "difference_report.print_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
